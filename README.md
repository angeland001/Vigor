# VIGOR

## neural_networks/visualizer.py (Explanation)

Visualizes movement data (joints) over time, representing the results of human movement of data generated by kinect.


## neural_networks/prediction_visualizer.py (Explanation)

Visualizes movement data (joints) over time, representing the results of a neural network prediction.

## neural_networks/temporal_cnn.py (Explanation)

Machine Learning Model built using Keras for predicting joint Cartesian coordinates based on a walking sequence provided in a JSON file. 

* Iterates through the joint Cartesian data to create input sequences (X) and corresponding labels (y) for training.
* Reshape the data into NumPy arrays.

***The overall goal of the code is to create, compile, and train a neural network model for predicting joint Cartesian coordinates based on a walking sequence, using a convolutional neural network (CNN) architecture. The mean squared error is used as the loss function, and the Adam optimizer is employed for training the model. The training data consists of input sequences (X) and corresponding labels (y).***

## neural_networks/train_wgan.py (Explanation)

Implements a Wasserstein Generative Adversarial Network (WGAN) for training on a dataset of joint data from motion capture (Mocap using kinect) in the context of generating movement data.

### Load and Preprocess Data:

* Use glob to get file paths for all CSV files in the "data" directory.
* Initialize variables: X_train (initially set to None), scaler (a MinMaxScaler class), joint_scalers (a list to store individual joint scalers), and batch_size.
* Read the first 500 lines from each CSV file in the "data" directory, concatenate them, and store them in readlines_arr.
* Process each line in readlines_arr: remove newline characters, split by comma, convert values to float, truncate to 72 values, and append to X_train.

### Feature Scaling:

* Reshape X_train to have 72 columns.
* Transpose the matrix so that it has dimensions (72, number of samples).
* For each joint, create a MinMaxScaler (this_joint_mms), fit it to the joint data, transform the data, and append the scaled joint data to new_X.
* Convert new_X to a NumPy array and reshape it to have dimensions (72, number of samples).
* Transpose the matrix back to the original shape.

### Data Preparation for WGAN:
* Reshape X to have dimensions (-1, 100, 24, 3), where 100 is the sequence length, 24 is the number of joints, and 3 is the number of coordinates.
* After, Train the model.

***Loads joint data from motion capture, preprocesses it (including feature scaling for each joint), and uses a Wasserstein Generative Adversarial Network (WGAN) to generate synthetic data. The WGAN is trained on the preprocessed data for a specified number of epochs, and samples are generated and saved at regular intervals during training.***

## neural_networks/wgan_choreo_2.py (Explanation)

The line wgan.train(epochs=10000, batch_size=8, sample_interval=120) is calling the train method of the WGAN class instance (wgan).

* wgan: An instance of the WGAN class, which is an implementation of a Wasserstein Generative Adversarial Network (WGAN).
* .train(epochs=10000, batch_size=8, sample_interval=120): Calls the train method of the WGAN instance with the following parameters:
* epochs=10000: The number of training epochs, specifying how many times the generator and critic models will be updated during training.
* batch_size=8: The number of samples used in each iteration of training. The critic is updated multiple times per generator update (n_critic times).
* sample_interval=120: Specifies how often (in terms of epochs) to save and generate samples during training. In this case, samples will be saved every 120 epochs.

***The train method is responsible for training the WGAN by iteratively updating the generator and critic models. It loads the training data, preprocesses it, and uses the Wasserstein loss for training. Additionally, it includes logic to save generated samples at specified intervals. The training process involves training the discriminator (critic) multiple times for each generator update, as is typical in Wasserstein GANs.***

***The line essentially initiates the training process for the WGAN instance, specifying the training configuration such as the number of epochs, batch size, and sample interval.***

## neural_networks/networks/ae/XYZ-v1/gta.py (Explanation)

Loads ground truth and prediction data from CSV files, reshapes the data, calculates the Euclidean distance between corresponding points in the datasets, and prints the resulting distance. This kind of distance metric is often used to assess how well a model's predictions match the ground truth or target values.

## neural_networks/networks/ae/XYZ-v1/old_target.py (Explanation)

* Opens a JSON file (read + '.json') and loads its content into a Python dictionary named userdata.
* For each frame (out of 5000) and each joint in the range of "45", it applies the transform function to the Euler angles of the joint and writes the transformed values to a CSV file (write + '.csv'). The transformed values are cosines of half of the original angles. (Pretty sure this is to account for angles when limbs are shifting around in angles and/or in front of other limbs
* The transform function takes an angle (data), halves it, converts it to radians, and then calculates the cosine. If the original angle is greater than 180 degrees, it multiplies the cosine by -1.
*  the convert function is called with the JSON file path as 'JSONs/ae-naturalwalk-1.json' and the CSV file name as 'target'. This initiates the conversion process, applying the specified transformations and writing the results to a CSV file.

***The code converts Euler angles from a JSON file, applies specific transformations, and writes the transformed data to a CSV file. The transformations involve halving the angle, converting it to radians, and taking the cosine, with a special handling for angles greater than 180 degrees.***

## neural_networks/networks/ae/XYZ-v1/old_training.py (Explanation)

**Similar to old_target.py but modification is different**

```
for joint in "0123":
    if joint in "45":
        save_file.write("0.0,0.0,0.0,")
    else:
        # ... (rest of the code remains the same)
```

* The code iterates over joints labeled as "0123". If the current joint is in "45", it writes a placeholder of "0.0,0.0,0.0," to the CSV file. Otherwise, it proceeds to write the transformed Euler angles for that joint.
This modification ensures that joints labeled as "4" and "5" receive a placeholder value of "0.0,0.0,0.0," instead of writing the transformed Euler angles.
* Convert function with the JSON file path as 'JSONs/ae-naturalwalk-1.json' and the CSV file name as 'training-transformed'. The purpose is to initiate the conversion process with the updated joint handling.

***the code converts Euler angles from a JSON file, applies specific transformations, and writes the transformed data to a CSV file. The modification ensures that for joints labeled as "4" and "5", a placeholder value of "0.0,0.0,0.0," is written instead of the transformed Euler angles.***

## neural_networks/networks/ae/XYZ-v1/predict.py (Explanation)

* The code loads a pre-trained denoising autoencoder model from the file "Models/dae-xyz-gta.h5" using the load_model function from Keras.
    *  Uses model trained by autoencoder-gtadimensions.py  for denoising

```
training_file = open('CSVs/training-gta.csv', 'r')
training_data = []

for line in training_file.readlines():
    for data in line.split(","):
        if data != "\n" or data != "":
            try:
                training_data.append(float(data))
            except ValueError:
                pass
training_data = np.reshape(training_data, (-1, 18, 1))

```
* reads training data from the file "CSVs/training-gta.csv". It processes the data by converting it to a flat list of floats and then reshapes it into a NumPy array with the shape (-1, 18, 1). This reshaping is consistent with the expected input format for the autoencoder.

```
prediction_file = open('CSVs/prediction-gta.csv', 'w')
prediction_data = np.reshape(prediction_data, (-1, 18, 1))

for frame in prediction_data:
    for data in frame:
        prediction_file.write(str(data[0]))
        prediction_file.write(",")
    prediction_file.write("\n")


```

* opens a new CSV file "CSVs/prediction-gta.csv" for writing.
    * It reshapes the prediction data to match the expected format and then iterates through the frames and data points in the prediction. For each data point, it writes the value to the CSV file, separated by commas, and appends a newline character at the end of each frame.
    *  iterates through the frames and data points in the prediction. For each data point, it writes the value to the CSV file, separated by commas, and appends a newline character at the end of each frame.
 
***this code loads a pre-trained denoising autoencoder model, reads training data from a CSV file, generates predictions using the autoencoder, and writes the predicted data to a new CSV file. The resulting CSV file contains the reconstructed data predicted by the autoencoder based on the input training data.***

 
## neural_networks/networks/ae/XYZ-v1/target_writer.py (Explanation)

This code reads joint data from a JSON file and writes specific joint coordinates to a CSV file.

***Extracts joint coordinates from a JSON file representing motion capture data, specifically targeting joints with indices 12, 13, 14, 16, 17, and 18. It then writes these joint coordinates to a CSV file, where each row corresponds to a frame, and the columns contain x, y, and z coordinates for the specified joints.***


## neural_networks/networks/ae/XYZ-v1/training_writer.py (Explanation)

***Extracts joint coordinates from a JSON file representing motion capture data, specifically targeting joints with indices 4, 5, 6, 8, 9, and 10. It then writes these joint coordinates to a CSV file, where each row corresponds to a frame, and the columns contain x, y, and z coordinates for the specified joints. The purpose of this code is likely to prepare data for training or analysis, focusing on a subset of joints from the motion capture data.***


# TO DO FOR VIGOR TEAMMATES

With neural_networks/networks/ae/XYZ-v1/autoencoder-gtadimensions.py, You guys in backend will attempt to train a model using the training and testing data produced in CSV from previous data gathering. Look in autoencoder-gtadimensions.py to get started

***NOTE: I have added hints on what you need to accomplish but google will be your best friend. Most everyone cannot memorize everything in one go so it takes practice! Experiment and see where it goes. Hopefully you'll have a working trained model to use for predictions in predict.py***








